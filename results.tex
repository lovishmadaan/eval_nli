\section{Results}

\begin{itemize}
  \item Final pre-trained model result analysis. How model size, prompts, and shots affect things across various tasks.
  \item Development of model performance for a given task across model sizes.
  \item Correlation of model performance development with other commonsense/normal reasoning tasks (race, obqa, mmlu, math, etc.)
  \item Results on ChaosNLI and how model scores relate to the distribution of human judgements. Model size/prompt analysis for this too.
  \item Large models are good, but is it because of better models/training or just contamination? Contamination Analysis on various benchmarks.
  \item Can NLI tasks help in pre-training ablations? Results on seed models and models trained on different datamixes. How does the effectiveness of a given dataset/datamix is affected under different datasets (both commonsense reasoning and standard datasets).
\end{itemize}
